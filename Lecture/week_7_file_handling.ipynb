{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LU Logo](https://www.df.lu.lv/fileadmin/user_upload/LU.LV/Apaksvietnes/Fakultates/www.df.lu.lv/Par_mums/Logo/DF_logo/01_DF_logo_LV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: File Handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Overview\n",
    "\n",
    "We will cover the following topics:\n",
    "\n",
    "* Folder / directory operations: creating, renaming, deleting, listing.\n",
    "  * Path from pathlib, glob and rglob\n",
    "* Reading from, appending and writing to text files.\n",
    "  * Encoding issues\n",
    "* Binary files\n",
    "* JSON files\n",
    "\n",
    "## Lesson Objectives\n",
    "\n",
    "To learn how to:\n",
    "* Work with folders / directories\n",
    "* Work with files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.16 (main, Dec  7 2022, 02:40:58) \n",
      "[Clang 11.0.3 (clang-1103.0.32.62)]\n"
     ]
    }
   ],
   "source": [
    "# generally imports go at the top of a notebook\n",
    "# python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 1: - Folder / Directory Operations\n",
    "\n",
    "* [pathlib](https://docs.python.org/3/library/pathlib.html) – Object-oriented filesystem paths\n",
    "* [os](https://docs.python.org/3/library/os.html) – Various operating system interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the required Path object\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_module.py\n",
      "test_data.json\n",
      "week_2_key_programming_concepts.ipynb\n",
      "week_1_example.py\n",
      "my_module2.py\n",
      "__pycache__\n",
      "data.csv\n",
      "README.md\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_8_classes_objects.ipynb\n",
      ".ipynb_checkpoints\n",
      "week_1_Python_basics.ipynb\n",
      "week_7_file_handling.ipynb\n",
      "week_5_standard_library_modules.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Listing contents of the current working directory\n",
    "\n",
    "# Current directory path\n",
    "cur_dir = Path(\".\")\n",
    "\n",
    "# List directory contents (in arbitrary order)\n",
    "for item in cur_dir.iterdir():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "README.md\n",
      "__pycache__\n",
      "data.csv\n",
      "my_module.py\n",
      "my_module2.py\n",
      "test_data.json\n",
      "week_1_Python_basics.ipynb\n",
      "week_1_example.py\n",
      "week_2_key_programming_concepts.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_5_standard_library_modules.ipynb\n",
      "week_7_file_handling.ipynb\n",
      "week_8_classes_objects.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Let's sort directory content list\n",
    "\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "README.md\n",
      "Test-directory\n",
      "__pycache__\n",
      "data.csv\n",
      "my_module.py\n",
      "my_module2.py\n",
      "test_data.json\n",
      "week_1_Python_basics.ipynb\n",
      "week_1_example.py\n",
      "week_2_key_programming_concepts.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_5_standard_library_modules.ipynb\n",
      "week_7_file_handling.ipynb\n",
      "week_8_classes_objects.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Make a new directory (under the current dir)\n",
    "\n",
    "new_dir = Path(\"Test-directory\")   # under the current dir by default\n",
    "new_dir.mkdir(exist_ok=True)       # it's OK if the directory already exists\n",
    "\n",
    "# Print current dir contents\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "README.md\n",
      "Test-directory-2\n",
      "__pycache__\n",
      "data.csv\n",
      "my_module.py\n",
      "my_module2.py\n",
      "test_data.json\n",
      "week_1_Python_basics.ipynb\n",
      "week_1_example.py\n",
      "week_2_key_programming_concepts.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_5_standard_library_modules.ipynb\n",
      "week_7_file_handling.ipynb\n",
      "week_8_classes_objects.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Rename a directory\n",
    "\n",
    "import os\n",
    "\n",
    "os.rename(\"Test-directory\", \"Test-directory-2\")\n",
    "\n",
    "# Print current dir contents\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a directory (it must be empty)\n",
    "\n",
    "new_dir = Path(\"Test-directory-2\")\n",
    "new_dir.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating some files and a directory for demonstrating filename matching operations.\n",
    "\n",
    "To create files, you would normally `open` the file in a write mode but here we will use the `touch()` method to create some empty files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory and some empty files\n",
    "\n",
    "Path(\"Test-directory\").mkdir()\n",
    "Path(\"Test-directory/sub_dir\").mkdir()\n",
    "\n",
    "Path(\"Test-directory/file1.docx\").touch()\n",
    "Path(\"Test-directory/file2.docx\").touch()\n",
    "Path(\"Test-directory/test1.py\").touch()\n",
    "Path(\"Test-directory/sub_dir/file1.docx\").touch()\n",
    "Path(\"Test-directory/sub_dir/file2.csv\").touch()\n",
    "Path(\"Test-directory/sub_dir/test3.csv\").touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "README.md\n",
      "Test-directory\n",
      "__pycache__\n",
      "data.csv\n",
      "my_module.py\n",
      "my_module2.py\n",
      "test_data.json\n",
      "week_1_Python_basics.ipynb\n",
      "week_1_example.py\n",
      "week_2_key_programming_concepts.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_5_standard_library_modules.ipynb\n",
      "week_7_file_handling.ipynb\n",
      "week_8_classes_objects.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Print current dir contents\n",
    "\n",
    "cur_dir = Path(\".\")\n",
    "\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PosixPath in module pathlib object:\n",
      "\n",
      "class PosixPath(Path, PurePosixPath)\n",
      " |  PosixPath(*args, **kwargs)\n",
      " |  \n",
      " |  Path subclass for non-Windows systems.\n",
      " |  \n",
      " |  On a POSIX system, instantiating a Path should return this object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PosixPath\n",
      " |      Path\n",
      " |      PurePosixPath\n",
      " |      PurePath\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from Path:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, t, v, tb)\n",
      " |  \n",
      " |  absolute(self)\n",
      " |      Return an absolute version of this path.  This function works\n",
      " |      even if the path doesn't point to anything.\n",
      " |      \n",
      " |      No normalization is done, i.e. all '.' and '..' will be kept along.\n",
      " |      Use resolve() to get the canonical path to a file.\n",
      " |  \n",
      " |  chmod(self, mode)\n",
      " |      Change the permissions of the path, like os.chmod().\n",
      " |  \n",
      " |  exists(self)\n",
      " |      Whether this path exists.\n",
      " |  \n",
      " |  expanduser(self)\n",
      " |      Return a new path with expanded ~ and ~user constructs\n",
      " |      (as returned by os.path.expanduser)\n",
      " |  \n",
      " |  glob(self, pattern)\n",
      " |      Iterate over this subtree and yield all existing files (of any\n",
      " |      kind, including directories) matching the given relative pattern.\n",
      " |  \n",
      " |  group(self)\n",
      " |      Return the group name of the file gid.\n",
      " |  \n",
      " |  is_block_device(self)\n",
      " |      Whether this path is a block device.\n",
      " |  \n",
      " |  is_char_device(self)\n",
      " |      Whether this path is a character device.\n",
      " |  \n",
      " |  is_dir(self)\n",
      " |      Whether this path is a directory.\n",
      " |  \n",
      " |  is_fifo(self)\n",
      " |      Whether this path is a FIFO.\n",
      " |  \n",
      " |  is_file(self)\n",
      " |      Whether this path is a regular file (also True for symlinks pointing\n",
      " |      to regular files).\n",
      " |  \n",
      " |  is_mount(self)\n",
      " |      Check if this path is a POSIX mount point\n",
      " |  \n",
      " |  is_socket(self)\n",
      " |      Whether this path is a socket.\n",
      " |  \n",
      " |  is_symlink(self)\n",
      " |      Whether this path is a symbolic link.\n",
      " |  \n",
      " |  iterdir(self)\n",
      " |      Iterate over the files in this directory.  Does not yield any\n",
      " |      result for the special paths '.' and '..'.\n",
      " |  \n",
      " |  lchmod(self, mode)\n",
      " |      Like chmod(), except if the path points to a symlink, the symlink's\n",
      " |      permissions are changed, rather than its target's.\n",
      " |  \n",
      " |  link_to(self, target)\n",
      " |      Make the target path a hard link pointing to this path.\n",
      " |      \n",
      " |      Note this function does not make this path a hard link to *target*,\n",
      " |      despite the implication of the function and argument names. The order\n",
      " |      of arguments (target, link) is the reverse of Path.symlink_to, but\n",
      " |      matches that of os.link.\n",
      " |  \n",
      " |  lstat(self)\n",
      " |      Like stat(), except if the path points to a symlink, the symlink's\n",
      " |      status information is returned, rather than its target's.\n",
      " |  \n",
      " |  mkdir(self, mode=511, parents=False, exist_ok=False)\n",
      " |      Create a new directory at this given path.\n",
      " |  \n",
      " |  open(self, mode='r', buffering=-1, encoding=None, errors=None, newline=None)\n",
      " |      Open the file pointed by this path and return a file object, as\n",
      " |      the built-in open() function does.\n",
      " |  \n",
      " |  owner(self)\n",
      " |      Return the login name of the file owner.\n",
      " |  \n",
      " |  read_bytes(self)\n",
      " |      Open the file in bytes mode, read it, and close the file.\n",
      " |  \n",
      " |  read_text(self, encoding=None, errors=None)\n",
      " |      Open the file in text mode, read it, and close the file.\n",
      " |  \n",
      " |  readlink(self)\n",
      " |      Return the path to which the symbolic link points.\n",
      " |  \n",
      " |  rename(self, target)\n",
      " |      Rename this path to the target path.\n",
      " |      \n",
      " |      The target path may be absolute or relative. Relative paths are\n",
      " |      interpreted relative to the current working directory, *not* the\n",
      " |      directory of the Path object.\n",
      " |      \n",
      " |      Returns the new Path instance pointing to the target path.\n",
      " |  \n",
      " |  replace(self, target)\n",
      " |      Rename this path to the target path, overwriting if that path exists.\n",
      " |      \n",
      " |      The target path may be absolute or relative. Relative paths are\n",
      " |      interpreted relative to the current working directory, *not* the\n",
      " |      directory of the Path object.\n",
      " |      \n",
      " |      Returns the new Path instance pointing to the target path.\n",
      " |  \n",
      " |  resolve(self, strict=False)\n",
      " |      Make the path absolute, resolving all symlinks on the way and also\n",
      " |      normalizing it (for example turning slashes into backslashes under\n",
      " |      Windows).\n",
      " |  \n",
      " |  rglob(self, pattern)\n",
      " |      Recursively yield all existing files (of any kind, including\n",
      " |      directories) matching the given relative pattern, anywhere in\n",
      " |      this subtree.\n",
      " |  \n",
      " |  rmdir(self)\n",
      " |      Remove this directory.  The directory must be empty.\n",
      " |  \n",
      " |  samefile(self, other_path)\n",
      " |      Return whether other_path is the same or not as this file\n",
      " |      (as returned by os.path.samefile()).\n",
      " |  \n",
      " |  stat(self)\n",
      " |      Return the result of the stat() system call on this path, like\n",
      " |      os.stat() does.\n",
      " |  \n",
      " |  symlink_to(self, target, target_is_directory=False)\n",
      " |      Make this path a symlink pointing to the target path.\n",
      " |      Note the order of arguments (link, target) is the reverse of os.symlink.\n",
      " |  \n",
      " |  touch(self, mode=438, exist_ok=True)\n",
      " |      Create this file with the given access mode, if it doesn't exist.\n",
      " |  \n",
      " |  unlink(self, missing_ok=False)\n",
      " |      Remove this file or link.\n",
      " |      If the path is a directory, use rmdir() instead.\n",
      " |  \n",
      " |  write_bytes(self, data)\n",
      " |      Open the file in bytes mode, write to it, and close the file.\n",
      " |  \n",
      " |  write_text(self, data, encoding=None, errors=None)\n",
      " |      Open the file in text mode, write to it, and close the file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from Path:\n",
      " |  \n",
      " |  cwd() from builtins.type\n",
      " |      Return a new path pointing to the current working directory\n",
      " |      (as returned by os.getcwd()).\n",
      " |  \n",
      " |  home() from builtins.type\n",
      " |      Return a new path pointing to the user's home directory (as\n",
      " |      returned by os.path.expanduser('~')).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from Path:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Construct a PurePath from one or several strings and or existing\n",
      " |      PurePath objects.  The strings and path objects are combined so as\n",
      " |      to yield a canonicalized path, which is incorporated into the\n",
      " |      new PurePath object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from PurePath:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return the bytes representation of the path.  This is only\n",
      " |      recommended to use under Unix.\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __fspath__(self)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rtruediv__(self, key)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return the string representation of the path, suitable for\n",
      " |      passing to system calls.\n",
      " |  \n",
      " |  __truediv__(self, key)\n",
      " |  \n",
      " |  as_posix(self)\n",
      " |      Return the string representation of the path with forward (/)\n",
      " |      slashes.\n",
      " |  \n",
      " |  as_uri(self)\n",
      " |      Return the path as a 'file' URI.\n",
      " |  \n",
      " |  is_absolute(self)\n",
      " |      True if the path is absolute (has both a root and, if applicable,\n",
      " |      a drive).\n",
      " |  \n",
      " |  is_relative_to(self, *other)\n",
      " |      Return True if the path is relative to another path or False.\n",
      " |  \n",
      " |  is_reserved(self)\n",
      " |      Return True if the path contains one of the special names reserved\n",
      " |      by the system, if any.\n",
      " |  \n",
      " |  joinpath(self, *args)\n",
      " |      Combine this path with one or several arguments, and return a\n",
      " |      new path representing either a subpath (if all arguments are relative\n",
      " |      paths) or a totally different path (if one of the arguments is\n",
      " |      anchored).\n",
      " |  \n",
      " |  match(self, path_pattern)\n",
      " |      Return True if this path matches the given pattern.\n",
      " |  \n",
      " |  relative_to(self, *other)\n",
      " |      Return the relative path to another path identified by the passed\n",
      " |      arguments.  If the operation is not possible (because this is not\n",
      " |      a subpath of the other path), raise ValueError.\n",
      " |  \n",
      " |  with_name(self, name)\n",
      " |      Return a new path with the file name changed.\n",
      " |  \n",
      " |  with_stem(self, stem)\n",
      " |      Return a new path with the stem changed.\n",
      " |  \n",
      " |  with_suffix(self, suffix)\n",
      " |      Return a new path with the file suffix changed.  If the path\n",
      " |      has no suffix, add given suffix.  If the given suffix is an empty\n",
      " |      string, remove the suffix from the path.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from PurePath:\n",
      " |  \n",
      " |  __class_getitem__(type) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from PurePath:\n",
      " |  \n",
      " |  anchor\n",
      " |      The concatenation of the drive and root, or ''.\n",
      " |  \n",
      " |  drive\n",
      " |      The drive prefix (letter or UNC path), if any.\n",
      " |  \n",
      " |  name\n",
      " |      The final path component, if any.\n",
      " |  \n",
      " |  parent\n",
      " |      The logical parent of the path.\n",
      " |  \n",
      " |  parents\n",
      " |      A sequence of this path's logical parents.\n",
      " |  \n",
      " |  parts\n",
      " |      An object providing sequence-like access to the\n",
      " |      components in the filesystem path.\n",
      " |  \n",
      " |  root\n",
      " |      The root of the path, if any.\n",
      " |  \n",
      " |  stem\n",
      " |      The final path component, minus its last suffix.\n",
      " |  \n",
      " |  suffix\n",
      " |      The final component's last suffix, if any.\n",
      " |      \n",
      " |      This includes the leading period. For example: '.txt'\n",
      " |  \n",
      " |  suffixes\n",
      " |      A list of the final component's suffixes, if any.\n",
      " |      \n",
      " |      These include the leading periods. For example: ['.tar', '.gz']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See help for additional information about Path objects\n",
    "\n",
    "help(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/captsolo/_changed_stuff_/Code/LU_Python_2023/notebooks'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filename pattern matching\n",
    "\n",
    "We want to search for files according to some filename pattern (e.g. `*.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no .docx files in the current directory\n",
    "#  - there will be no matches for this file pattern\n",
    "\n",
    "matches = cur_dir.glob(\"*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-directory/file1.docx\n",
      "Test-directory/file2.docx\n"
     ]
    }
   ],
   "source": [
    "# Let's tell Python to look for matches in any directory\n",
    "#  - there will be matches in the \"Test-directory\" directory \n",
    "#  - but Python will not search recursively (in further subdirectories)\n",
    "\n",
    "matches = cur_dir.glob(\"*/*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-directory/file1.docx\n",
      "Test-directory/file2.docx\n",
      "Test-directory/sub_dir/file1.docx\n"
     ]
    }
   ],
   "source": [
    "# We want to find matches recursively, in any subdirectory\n",
    "#  - for this purpose we can use the \"**\" directory pattern\n",
    "\n",
    "matches = cur_dir.glob(\"**/*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-directory/file1.docx\n",
      "Test-directory/file2.docx\n",
      "Test-directory/sub_dir/file1.docx\n"
     ]
    }
   ],
   "source": [
    "# rglob() is like calling glob() with \"**/\" added in front of the filename pattern\n",
    "\n",
    "matches = cur_dir.rglob(\"*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: .\n",
      "    my_module.py\n",
      "    test_data.json\n",
      "    week_2_key_programming_concepts.ipynb\n",
      "    week_1_example.py\n",
      "    my_module2.py\n",
      "    data.csv\n",
      "    README.md\n",
      "    week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "    week_8_classes_objects.ipynb\n",
      "    week_1_Python_basics.ipynb\n",
      "    week_7_file_handling.ipynb\n",
      "    week_5_standard_library_modules.ipynb\n",
      "Directory: ./__pycache__\n",
      "    my_module.cpython-39.pyc\n",
      "    my_module2.cpython-39.pyc\n",
      "Directory: ./.ipynb_checkpoints\n",
      "    week_7_file_handling-checkpoint.ipynb\n",
      "    week_2_key_programming_concepts-checkpoint.ipynb\n",
      "    week_1_example-checkpoint.py\n",
      "    week_8_classes_objects-checkpoint.ipynb\n",
      "    week_1_Python_basics-checkpoint.ipynb\n",
      "    week_5_standard_library_modules-checkpoint.ipynb\n",
      "    week_4_functions_tuples_dictionaries_sets-checkpoint.ipynb\n",
      "Directory: ./Test-directory\n",
      "    file2.docx\n",
      "    test1.py\n",
      "    file1.docx\n",
      "Directory: ./Test-directory/sub_dir\n",
      "    file2.csv\n",
      "    test3.csv\n",
      "    file1.docx\n"
     ]
    }
   ],
   "source": [
    "# We can also \"walk\" a directory tree using os.walk()\n",
    "\n",
    "import os\n",
    "\n",
    "# Walk a directory tree and print directory and file names\n",
    "for dirpath, dirnames, files in os.walk('.'):\n",
    "        print(f'Directory: {dirpath}')\n",
    "        for filename in files:\n",
    "            print(\"   \", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic 1 - mini exercise\n",
    "\n",
    "Choose a directory and explore its contents using the methods described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 2: - Reading from and writing to text files\n",
    "\n",
    "This topic will cover reading from, appending and writing to text files.\n",
    "\n",
    "Use Python's `with` statement to make sure the file is properly closed after opening:\n",
    "\n",
    "```\n",
    "with open(filename, \"w\") as file_object:\n",
    "    file_object.write(\"some text\")\n",
    "```\n",
    "\n",
    "We will also use Jupyter's command `%%writefile` to create a file to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_file.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_file.txt\n",
    "first,second,third\n",
    "1,2,3\n",
    "4,5,6\n",
    "7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using \"with\" for opening a file\n",
    "#  - \"r\" instructs to open the file for reading\n",
    "\n",
    "with open(\"test_file.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function open in module io:\n",
      "\n",
      "open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)\n",
      "    Open file and return a stream.  Raise OSError upon failure.\n",
      "    \n",
      "    file is either a text or byte string giving the name (and the path\n",
      "    if the file isn't in the current working directory) of the file to\n",
      "    be opened or an integer file descriptor of the file to be\n",
      "    wrapped. (If a file descriptor is given, it is closed when the\n",
      "    returned I/O object is closed, unless closefd is set to False.)\n",
      "    \n",
      "    mode is an optional string that specifies the mode in which the file\n",
      "    is opened. It defaults to 'r' which means open for reading in text\n",
      "    mode.  Other common values are 'w' for writing (truncating the file if\n",
      "    it already exists), 'x' for creating and writing to a new file, and\n",
      "    'a' for appending (which on some Unix systems, means that all writes\n",
      "    append to the end of the file regardless of the current seek position).\n",
      "    In text mode, if encoding is not specified the encoding used is platform\n",
      "    dependent: locale.getpreferredencoding(False) is called to get the\n",
      "    current locale encoding. (For reading and writing raw bytes use binary\n",
      "    mode and leave encoding unspecified.) The available modes are:\n",
      "    \n",
      "    ========= ===============================================================\n",
      "    Character Meaning\n",
      "    --------- ---------------------------------------------------------------\n",
      "    'r'       open for reading (default)\n",
      "    'w'       open for writing, truncating the file first\n",
      "    'x'       create a new file and open it for writing\n",
      "    'a'       open for writing, appending to the end of the file if it exists\n",
      "    'b'       binary mode\n",
      "    't'       text mode (default)\n",
      "    '+'       open a disk file for updating (reading and writing)\n",
      "    'U'       universal newline mode (deprecated)\n",
      "    ========= ===============================================================\n",
      "    \n",
      "    The default mode is 'rt' (open for reading text). For binary random\n",
      "    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n",
      "    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n",
      "    raises an `FileExistsError` if the file already exists.\n",
      "    \n",
      "    Python distinguishes between files opened in binary and text modes,\n",
      "    even when the underlying operating system doesn't. Files opened in\n",
      "    binary mode (appending 'b' to the mode argument) return contents as\n",
      "    bytes objects without any decoding. In text mode (the default, or when\n",
      "    't' is appended to the mode argument), the contents of the file are\n",
      "    returned as strings, the bytes having been first decoded using a\n",
      "    platform-dependent encoding or using the specified encoding if given.\n",
      "    \n",
      "    'U' mode is deprecated and will raise an exception in future versions\n",
      "    of Python.  It has no effect in Python 3.  Use newline to control\n",
      "    universal newlines mode.\n",
      "    \n",
      "    buffering is an optional integer used to set the buffering policy.\n",
      "    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n",
      "    line buffering (only usable in text mode), and an integer > 1 to indicate\n",
      "    the size of a fixed-size chunk buffer.  When no buffering argument is\n",
      "    given, the default buffering policy works as follows:\n",
      "    \n",
      "    * Binary files are buffered in fixed-size chunks; the size of the buffer\n",
      "      is chosen using a heuristic trying to determine the underlying device's\n",
      "      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n",
      "      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n",
      "    \n",
      "    * \"Interactive\" text files (files for which isatty() returns True)\n",
      "      use line buffering.  Other text files use the policy described above\n",
      "      for binary files.\n",
      "    \n",
      "    encoding is the name of the encoding used to decode or encode the\n",
      "    file. This should only be used in text mode. The default encoding is\n",
      "    platform dependent, but any encoding supported by Python can be\n",
      "    passed.  See the codecs module for the list of supported encodings.\n",
      "    \n",
      "    errors is an optional string that specifies how encoding errors are to\n",
      "    be handled---this argument should not be used in binary mode. Pass\n",
      "    'strict' to raise a ValueError exception if there is an encoding error\n",
      "    (the default of None has the same effect), or pass 'ignore' to ignore\n",
      "    errors. (Note that ignoring encoding errors can lead to data loss.)\n",
      "    See the documentation for codecs.register or run 'help(codecs.Codec)'\n",
      "    for a list of the permitted encoding error strings.\n",
      "    \n",
      "    newline controls how universal newlines works (it only applies to text\n",
      "    mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works as\n",
      "    follows:\n",
      "    \n",
      "    * On input, if newline is None, universal newlines mode is\n",
      "      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
      "      these are translated into '\\n' before being returned to the\n",
      "      caller. If it is '', universal newline mode is enabled, but line\n",
      "      endings are returned to the caller untranslated. If it has any of\n",
      "      the other legal values, input lines are only terminated by the given\n",
      "      string, and the line ending is returned to the caller untranslated.\n",
      "    \n",
      "    * On output, if newline is None, any '\\n' characters written are\n",
      "      translated to the system default line separator, os.linesep. If\n",
      "      newline is '' or '\\n', no translation takes place. If newline is any\n",
      "      of the other legal values, any '\\n' characters written are translated\n",
      "      to the given string.\n",
      "    \n",
      "    If closefd is False, the underlying file descriptor will be kept open\n",
      "    when the file is closed. This does not work when a file name is given\n",
      "    and must be True in that case.\n",
      "    \n",
      "    A custom opener can be used by passing a callable as *opener*. The\n",
      "    underlying file descriptor for the file object is then obtained by\n",
      "    calling *opener* with (*file*, *flags*). *opener* must return an open\n",
      "    file descriptor (passing os.open as *opener* results in functionality\n",
      "    similar to passing None).\n",
      "    \n",
      "    open() returns a file object whose type depends on the mode, and\n",
      "    through which the standard file operations such as reading and writing\n",
      "    are performed. When open() is used to open a file in a text mode ('w',\n",
      "    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n",
      "    a file in a binary mode, the returned class varies: in read binary\n",
      "    mode, it returns a BufferedReader; in write binary and append binary\n",
      "    modes, it returns a BufferedWriter, and in read/write mode, it returns\n",
      "    a BufferedRandom.\n",
      "    \n",
      "    It is also possible to use a string or bytearray as a file for both\n",
      "    reading and writing. For strings StringIO can be used like a file\n",
      "    opened in a text mode, and for bytes a BytesIO can be used like a file\n",
      "    opened in a binary mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the \"encoding\" parameter to specify character encoding (usually \"utf-8\")\n",
    "\n",
    "with open(\"test_file.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "\n",
      "1,2,3\n",
      "\n",
      "4,5,6\n",
      "\n",
      "7,8,9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can also go through the file line-by-line\n",
    "\n",
    "with open(\"test_file.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n"
     ]
    }
   ],
   "source": [
    "# let's get rid of extra newline characters\n",
    "\n",
    "with open(\"test_file.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n"
     ]
    }
   ],
   "source": [
    "# Path objects can also be used in the open() function\n",
    "\n",
    "test_file = Path(\"test_file.txt\")\n",
    "\n",
    "with open(test_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to write to a file (overwriting its contents if the file exists) use open mode \"w\"\n",
    "\n",
    "text = \"\"\"\n",
    "This is another file.\n",
    "It contains lines of text.\n",
    "\"\"\"\n",
    "\n",
    "# let's use Path()\n",
    "write_file_path = Path(\"write_file.txt\")\n",
    "\n",
    "with open(write_file_path, \"w\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's check that the text has been written to the file\n",
    "\n",
    "with open(write_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files may also be open in the append mode \"a\". In this case, new content will\n",
    "# be appended at the end of th file.\n",
    "\n",
    "with open(write_file_path, \"a\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(\"We are appending text at the end of the file.\")\n",
    "    write_file.write(\"One more line here.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "We are appending text at the end of the file.One more line here.\n"
     ]
    }
   ],
   "source": [
    "# let's check file contents\n",
    "\n",
    "with open(write_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines got merged together. To write them on separate lines, \n",
    "# we need to add a newline character \"\\n\" to the end of the line.\n",
    "\n",
    "with open(write_file_path, \"a\", encoding=\"utf-8\") as write_file:\n",
    "\n",
    "    # add the newline character to start on a new line\n",
    "    write_file.write(\"\\n\")\n",
    "    \n",
    "    write_file.write(\"This text should be on a new line.\\n\")\n",
    "    write_file.write(\"One more line here.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "We are appending text at the end of the file.One more line here.\n",
      "This text should be on a new line.\n",
      "One more line here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(write_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is another file.\\nIt contains lines of text.\\nWe are appending text at the end of the file.One more line here.\\nThis text should be on a new line.\\nOne more line here.\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\nThis is another file.\\nIt contains lines of text.\\nWe are appending text at the end of the file.One more line here.\\nThis text should be on a new line.\\nOne more line here.\\n'\n"
     ]
    }
   ],
   "source": [
    "print(repr(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the files\n",
    "\n",
    "os.remove(\"test_file.txt\")\n",
    "\n",
    "write_file_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 3: - Reading and writing binary and other types of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary files\n",
    "\n",
    "To open binary files, append \"b\" to the file open mode.\n",
    "\n",
    "Binary files do not have an encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0123456789abcdef'\n"
     ]
    }
   ],
   "source": [
    "# create a bytes object\n",
    "data = b'0123456789abcdef'\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "\n",
    "write_binary_path = Path(\"write_file.bin\")\n",
    "\n",
    "with open(write_binary_path, \"wb\") as write_file:\n",
    "    write_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0123456789abcdef'\n"
     ]
    }
   ],
   "source": [
    "# read the file\n",
    "\n",
    "with open(write_binary_path, \"rb\") as read_file:\n",
    "    data_read = read_file.read()\n",
    "    print(data_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'8'\n",
      "\n",
      "b'd'\n"
     ]
    }
   ],
   "source": [
    "# use seek() to go to a given position in the file\n",
    "\n",
    "with open(write_binary_path, \"rb\") as read_file:\n",
    "\n",
    "    # go to position 8 and read 1 byte\n",
    "    read_file.seek(8)\n",
    "    print(read_file.read(1))\n",
    "\n",
    "    print()\n",
    "\n",
    "    # go to position 3 from the end and read 1 byte\n",
    "    read_file.seek(-3, 2)\n",
    "    print(read_file.read(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_file.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_file.txt\n",
    "first,second,third\n",
    "1,2,3\n",
    "4,5,6\n",
    "7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'first,second,third\\n1,2,3\\n4,5,6\\n7,8,9\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_file.txt\", \"rb\") as read_file:\n",
    "    data_read = read_file.read()\n",
    "    print(data_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on bytes object:\n",
      "\n",
      "class bytes(object)\n",
      " |  bytes(iterable_of_ints) -> bytes\n",
      " |  bytes(string, encoding[, errors]) -> bytes\n",
      " |  bytes(bytes_or_buffer) -> immutable copy of bytes_or_buffer\n",
      " |  bytes(int) -> bytes object of size given by the parameter initialized with null bytes\n",
      " |  bytes() -> empty bytes object\n",
      " |  \n",
      " |  Construct an immutable array of bytes from:\n",
      " |    - an iterable yielding integers in range(256)\n",
      " |    - a text string encoded using the specified encoding\n",
      " |    - any object implementing the buffer API.\n",
      " |    - an integer\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(...)\n",
      " |      B.capitalize() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with only its first character capitalized (ASCII)\n",
      " |      and the rest lower-cased.\n",
      " |  \n",
      " |  center(self, width, fillchar=b' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character.\n",
      " |  \n",
      " |  count(...)\n",
      " |      B.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of subsection sub in\n",
      " |      bytes B[start:end].  Optional arguments start and end are interpreted\n",
      " |      as in slice notation.\n",
      " |  \n",
      " |  decode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Decode the bytes using the codec registered for encoding.\n",
      " |      \n",
      " |      encoding\n",
      " |        The encoding with which to decode the bytes.\n",
      " |      errors\n",
      " |        The error handling scheme to use for the handling of decoding errors.\n",
      " |        The default is 'strict' meaning that decoding errors raise a\n",
      " |        UnicodeDecodeError. Other possible values are 'ignore' and 'replace'\n",
      " |        as well as any other name registered with codecs.register_error that\n",
      " |        can handle UnicodeDecodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      B.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if B ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test B beginning at that position.\n",
      " |      With optional end, stop comparing B at that position.\n",
      " |      suffix can also be a tuple of bytes to try.\n",
      " |  \n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |      \n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      B.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  hex(...)\n",
      " |      Create a str of hexadecimal numbers from a bytes object.\n",
      " |      \n",
      " |        sep\n",
      " |          An optional single character or byte to separate hex bytes.\n",
      " |        bytes_per_sep\n",
      " |          How many bytes between separators.  Positive values count from the\n",
      " |          right, negative values count from the left.\n",
      " |      \n",
      " |      Example:\n",
      " |      >>> value = b'\\xb9\\x01\\xef'\n",
      " |      >>> value.hex()\n",
      " |      'b901ef'\n",
      " |      >>> value.hex(':')\n",
      " |      'b9:01:ef'\n",
      " |      >>> value.hex(':', 2)\n",
      " |      'b9:01ef'\n",
      " |      >>> value.hex(':', -2)\n",
      " |      'b901:ef'\n",
      " |  \n",
      " |  index(...)\n",
      " |      B.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the subsection is not found.\n",
      " |  \n",
      " |  isalnum(...)\n",
      " |      B.isalnum() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are alphanumeric\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  isalpha(...)\n",
      " |      B.isalpha() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are alphabetic\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  isascii(...)\n",
      " |      B.isascii() -> bool\n",
      " |      \n",
      " |      Return True if B is empty or all characters in B are ASCII,\n",
      " |      False otherwise.\n",
      " |  \n",
      " |  isdigit(...)\n",
      " |      B.isdigit() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are digits\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  islower(...)\n",
      " |      B.islower() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in B are lowercase and there is\n",
      " |      at least one cased character in B, False otherwise.\n",
      " |  \n",
      " |  isspace(...)\n",
      " |      B.isspace() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are whitespace\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  istitle(...)\n",
      " |      B.istitle() -> bool\n",
      " |      \n",
      " |      Return True if B is a titlecased string and there is at least one\n",
      " |      character in B, i.e. uppercase characters may only follow uncased\n",
      " |      characters and lowercase characters only cased ones. Return False\n",
      " |      otherwise.\n",
      " |  \n",
      " |  isupper(...)\n",
      " |      B.isupper() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in B are uppercase and there is\n",
      " |      at least one cased character in B, False otherwise.\n",
      " |  \n",
      " |  join(self, iterable_of_bytes, /)\n",
      " |      Concatenate any number of bytes objects.\n",
      " |      \n",
      " |      The bytes whose method is called is inserted in between each pair.\n",
      " |      \n",
      " |      The result is returned as a new bytes object.\n",
      " |      \n",
      " |      Example: b'.'.join([b'ab', b'pq', b'rs']) -> b'ab.pq.rs'.\n",
      " |  \n",
      " |  ljust(self, width, fillchar=b' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character.\n",
      " |  \n",
      " |  lower(...)\n",
      " |      B.lower() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with all ASCII characters converted to lowercase.\n",
      " |  \n",
      " |  lstrip(self, bytes=None, /)\n",
      " |      Strip leading bytes contained in the argument.\n",
      " |      \n",
      " |      If the argument is omitted or None, strip leading  ASCII whitespace.\n",
      " |  \n",
      " |  partition(self, sep, /)\n",
      " |      Partition the bytes into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator sep in the bytes. If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing the original bytes\n",
      " |      object and two empty bytes objects.\n",
      " |  \n",
      " |  removeprefix(self, prefix, /)\n",
      " |      Return a bytes object with the given prefix string removed if present.\n",
      " |      \n",
      " |      If the bytes starts with the prefix string, return bytes[len(prefix):].\n",
      " |      Otherwise, return a copy of the original bytes.\n",
      " |  \n",
      " |  removesuffix(self, suffix, /)\n",
      " |      Return a bytes object with the given suffix string removed if present.\n",
      " |      \n",
      " |      If the bytes ends with the suffix string and that suffix is not empty,\n",
      " |      return bytes[:-len(prefix)].  Otherwise, return a copy of the original\n",
      " |      bytes.\n",
      " |  \n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |      \n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |      \n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      B.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      B.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raise ValueError when the subsection is not found.\n",
      " |  \n",
      " |  rjust(self, width, fillchar=b' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character.\n",
      " |  \n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the bytes into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator sep in the bytes, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing two empty bytes\n",
      " |      objects and the original bytes object.\n",
      " |  \n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the sections in the bytes, using sep as the delimiter.\n",
      " |      \n",
      " |        sep\n",
      " |          The delimiter according which to split the bytes.\n",
      " |          None (the default value) means split on ASCII whitespace characters\n",
      " |          (space, tab, return, newline, formfeed, vertical tab).\n",
      " |        maxsplit\n",
      " |          Maximum number of splits to do.\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Splitting is done starting at the end of the bytes and working to the front.\n",
      " |  \n",
      " |  rstrip(self, bytes=None, /)\n",
      " |      Strip trailing bytes contained in the argument.\n",
      " |      \n",
      " |      If the argument is omitted or None, strip trailing ASCII whitespace.\n",
      " |  \n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the sections in the bytes, using sep as the delimiter.\n",
      " |      \n",
      " |      sep\n",
      " |        The delimiter according which to split the bytes.\n",
      " |        None (the default value) means split on ASCII whitespace characters\n",
      " |        (space, tab, return, newline, formfeed, vertical tab).\n",
      " |      maxsplit\n",
      " |        Maximum number of splits to do.\n",
      " |        -1 (the default value) means no limit.\n",
      " |  \n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the bytes, breaking at line boundaries.\n",
      " |      \n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      B.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if B starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test B beginning at that position.\n",
      " |      With optional end, stop comparing B at that position.\n",
      " |      prefix can also be a tuple of bytes to try.\n",
      " |  \n",
      " |  strip(self, bytes=None, /)\n",
      " |      Strip leading and trailing bytes contained in the argument.\n",
      " |      \n",
      " |      If the argument is omitted or None, strip leading and trailing ASCII whitespace.\n",
      " |  \n",
      " |  swapcase(...)\n",
      " |      B.swapcase() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with uppercase ASCII characters converted\n",
      " |      to lowercase ASCII and vice versa.\n",
      " |  \n",
      " |  title(...)\n",
      " |      B.title() -> copy of B\n",
      " |      \n",
      " |      Return a titlecased version of B, i.e. ASCII words start with uppercase\n",
      " |      characters, all remaining cased characters have lowercase.\n",
      " |  \n",
      " |  translate(self, table, /, delete=b'')\n",
      " |      Return a copy with each character mapped by the given translation table.\n",
      " |      \n",
      " |        table\n",
      " |          Translation table, which must be a bytes object of length 256.\n",
      " |      \n",
      " |      All characters occurring in the optional argument delete are removed.\n",
      " |      The remaining characters are mapped through the given translation table.\n",
      " |  \n",
      " |  upper(...)\n",
      " |      B.upper() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with all ASCII characters converted to uppercase.\n",
      " |  \n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |      \n",
      " |      The original string is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  fromhex(string, /) from builtins.type\n",
      " |      Create a bytes object from a string of hexadecimal numbers.\n",
      " |      \n",
      " |      Spaces between two numbers are accepted.\n",
      " |      Example: bytes.fromhex('B9 01EF') -> b'\\\\xb9\\\\x01\\\\xef'.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  maketrans(frm, to, /)\n",
      " |      Return a translation table useable for the bytes or bytearray translate method.\n",
      " |      \n",
      " |      The returned table will be one where each byte in frm is mapped to the byte at\n",
      " |      the same position in to.\n",
      " |      \n",
      " |      The bytes objects frm and to must be of the same length.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON files\n",
    "\n",
    "JSON (JavaScript Object Notation) files let us save Python data hierarchies (dictionaries, lists, ...) to a file / read them from a file.\n",
    "\n",
    "https://www.json.org/json-en.html\n",
    "\n",
    "To do this, we will use Python [json](https://docs.python.org/3/library/json.html) library:\n",
    "\n",
    "- json.dump() – save structured data to a JSON file\n",
    "- json.dumps() – return structured data as a JSON string\n",
    "- json.load() – read structured data from a JSON file\n",
    "- json.loads() – read structured data from a JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to be saved\n",
    "#  - a list containing a dictionary that contains a tuple\n",
    "\n",
    "data = ['foo', {'bar': ('baz', None, 1.0, 2)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foo', {'bar': ('baz', None, 1.0, 2)}]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bar': ('baz', None, 1.0, 2)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('baz', None, 1.0, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][\"bar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to a JSON file\n",
    "\n",
    "file_path = Path(\"test_data.json\")\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file_out:\n",
    "    json.dump(data, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]\n"
     ]
    }
   ],
   "source": [
    "# let's look at the file that we created\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file_in:\n",
    "    for line in file_in:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from a file\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file_in:\n",
    "    new_data = json.load(file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', {'bar': ['baz', None, 1.0, 2]}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baz', None, 1.0, 2]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[1]['bar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You can also transform Python data structures to / from JSON strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', {'bar': ('baz', None, 1.0, 2)}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str = json.dumps(data)\n",
    "json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', {'bar': ['baz', None, 1.0, 2]}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = json.loads(json_str)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV files\n",
    "\n",
    "CSV (comma separated values) files let us work with table-like files which consist of data cells usually separated by comma symbols.\n",
    "\n",
    "To do this, we will use Python [csv](https://docs.python.org/3/library/csv.html) library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = [[\"apple\", \"ābols\"], [\"pear\", \"bumbieris\"], [\"dog\", \"suns\"], [\"white\", \"balts\"], [\"black\", \"melns\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to open the CSV file for writing\n",
    "\n",
    "with open(\"data.csv\", \"w\") as out_file:\n",
    "    csv_file = csv.writer(out_file)\n",
    "\n",
    "    for item in data:\n",
    "        csv_file.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple,ābols\n",
      "pear,bumbieris\n",
      "dog,suns\n",
      "white,balts\n",
      "black,melns\n"
     ]
    }
   ],
   "source": [
    "# on Linux / Mac we can see file contents using the \"cat\" command\n",
    "!cat data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'ābols']\n",
      "['pear', 'bumbieris']\n",
      "['dog', 'suns']\n",
      "['white', 'balts']\n",
      "['black', 'melns']\n"
     ]
    }
   ],
   "source": [
    "# let's read this file\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(\"data.csv\", \"r\") as in_file:\n",
    "    csv_file = csv.reader(in_file)\n",
    "\n",
    "    for item in csv_file:\n",
    "        print(item)\n",
    "        data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'ābols'],\n",
       " ['pear', 'bumbieris'],\n",
       " ['dog', 'suns'],\n",
       " ['white', 'balts'],\n",
       " ['black', 'melns']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other file types\n",
    "\n",
    "Python supports many other file types including archives:\n",
    "\n",
    "- [gzip](https://docs.python.org/3/library/gzip.html) archive file support\n",
    "- [Python's zipfile: Manipulate Your ZIP Files Efficiently](https://realpython.com/python-zipfile/)\n",
    "\n",
    "Python's support for various archive formats allows you to read data directly from archive files without unarchiving it first. It can be useful when working with large (archived) files.\n",
    "\n",
    "There is also Python's [pickle library](https://docs.python.org/3/library/pickle.html) that allows us to save to disc custom / more complex Python objects (that can not be saved to JSON files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Overview\n",
    "\n",
    "In this lesson you learned:\n",
    "* How to work with directories in Python\n",
    "* How to work with text and binary files in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Dictionary comprehension\n",
    "\n",
    "Dictionary comprehension gives us a compact way for creating dictionaries\n",
    "- `{item[0]: item[1] for item in some_list if some_condition}`\n",
    "\n",
    "In this code snippet `item[0]` will become dictionary's key and `item[1]` will be the corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'ābols'],\n",
       " ['pear', 'bumbieris'],\n",
       " ['dog', 'suns'],\n",
       " ['white', 'balts'],\n",
       " ['black', 'melns']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 'ābols',\n",
       " 'pear': 'bumbieris',\n",
       " 'dog': 'suns',\n",
       " 'white': 'balts',\n",
       " 'black': 'melns'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without dictionary comprehension\n",
    "\n",
    "new_dict = {}\n",
    "\n",
    "for key, value in data:\n",
    "    new_dict[key] = value\n",
    "\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 'ābols',\n",
       " 'pear': 'bumbieris',\n",
       " 'dog': 'suns',\n",
       " 'white': 'balts',\n",
       " 'black': 'melns'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in 1 line using dictionary comprehension\n",
    "\n",
    "new_dict2 = {key: value for key, value in data}\n",
    "\n",
    "new_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'suns'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict2[\"dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Topic 1 - resources\n",
    "\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) - Object-oriented filesystem paths\n",
    "- [Working with files in Python](https://realpython.com/working-with-files-in-python/)\n",
    "\n",
    "### Topic 2 - resources\n",
    "\n",
    "- [Reading and writing files](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) - Python tutorial\n",
    "- [Reading and writing files](https://automatetheboringstuff.com/2e/chapter9/) - \"Automate the boring stuff with Python\" book\n",
    "- [Working with files in Python](https://realpython.com/working-with-files-in-python/)\n",
    "\n",
    "### Topic 3 - resources\n",
    "\n",
    "- [Reading binary files in Python](https://www.pythonmorsels.com/reading-binary-files-in-python/#top)\n",
    "- [gzip — Support for gzip files](https://docs.python.org/3/library/gzip.html)\n",
    "- [Working With JSON Data in Python](https://realpython.com/python-json/)\n",
    "- [Python's zipfile: Manipulate Your ZIP Files Efficiently](https://realpython.com/python-zipfile/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
